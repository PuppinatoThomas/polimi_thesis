Here is what holds in (and almost holds in) your data.

Part 1) Minimal functional dependencies that hold for all 100 rows

A. Postal consistency
- zip_code -> city
- zip_code -> state
- (city, state) -> zip_code

These are minimal (no attribute on the LHS can be dropped) and exact for all rows. In this sample, each zip maps to exactly one city and one state, and each (city, state) pair maps to exactly one zip.

B. Row keys observed in this sample (dataset-specific, but exact)
- brokered_by is unique across all 100 rows, so:
  brokered_by -> price, acre_lot, street, city, state, zip_code, house_size, prev_sold_date
- street values are also unique in this sample, so:
  street -> brokered_by, price, acre_lot, city, state, zip_code, house_size, prev_sold_date

Note: These “key” dependencies are minimal (single-attribute LHS) and do hold across all rows, but they are likely sample-specific rather than domain rules.


Part 2) Minimal relaxed dependencies

A. High-support exact-equality dependencies (with a few outliers)
The three numeric columns acre_lot, house_size, and price are nearly colinear for most rows:
- acre_lot -> price with price = 10,000 × acre_lot
  Support: 90% (90/100 rows exactly match)
  Exceptions (10 rows): brokered_by in {82978, 53138, 48807, 96817, 22217, 22721, 68269, 2765, 687, 53232}
- acre_lot -> house_size with house_size = 1,000 × acre_lot
  Support: 90% (same 10 exceptions as above)
- house_size -> price with price = 10 × house_size
  Support: 90% (same 10 exceptions as above)

What the exceptions look like:
- Several rows with acre_lot = 12.0 or 53.0 have price ∈ {111000, 125600} and house_size ∈ {3321, 5551}, breaking the 10k/1k/10 scaling.
- All other rows follow the exact scaling price = 10 × house_size = 10,000 × acre_lot.

B. Same relationships but accepting small value differences (tolerances)
Small floating-point noise is present (e.g., 39.800000000000004). Allowing a small absolute tolerance tightens support further.

Set simple absolute tolerances:
- |price − 10,000 × acre_lot| ≤ 10,000
  Support: 98% (only the two rows with acre_lot = 53.0 and price = 111000 still violate; their gaps are ≈ 419,000)
- |house_size − 1,000 × acre_lot| ≤ 1,000
  Support: 98% (same two 53.0-acre rows remain outliers)
- |price − 10 × house_size| ≤ 10,000
  Support: ~90% (the rows with house_size = 3321 or 5551 still deviate far beyond 10,000; e.g., 111000 vs 10×5551 = 55510)

Alternative ratio-based view:
- price / acre_lot ≈ 10,000 for 98% of rows
- house_size / acre_lot ≈ 1,000 for 98% of rows
- price / house_size ≈ 10 for ~90% of rows

C. Near-keys (relaxed uniqueness)
- brokered_by: unique for 100/100 rows (exact key in this sample).
- street: unique for 100/100 rows (exact key in this sample).
These are exact here, but you’d typically not rely on brokered_by or street alone as universal keys across broader data.


Summary of what to keep
- Exact, minimal FDs to rely on: zip_code -> city, zip_code -> state, and (city, state) -> zip_code.
- Very strong relaxed numeric dependencies:
  - price ≈ 10,000 × acre_lot (98% within ±10k; 90% exact)
  - house_size ≈ 1,000 × acre_lot (98% within ±1k; 90% exact)
  - price ≈ 10 × house_size (90% exact; outliers are large)
- Specific outlier cluster to examine (10 rows): brokered_by in {82978, 53138, 48807, 96817, 22217, 22721, 68269, 2765, 687, 53232}. These likely carry mis-scaled house_size and/or price for acre_lot = 12.0 or 53.0.
